{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code and all my understandings and everything about magic. This is somehow my first serious work in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make these constants arguments\n",
    "n_route = 228\n",
    "n_hist = 12\n",
    "n_pred = 9\n",
    "batch_size = 50\n",
    "epoch = 50\n",
    "# parser.add_argument('--save', type=int, default=10)\n",
    "ks = 3  # spatial convolution kernel size\n",
    "kt = 3  # temporal convolution kernel size\n",
    "lr = 1e-3\n",
    "opt = torch.optim.RMSprop\n",
    "# parser.add_argument('--graph', type=str, default='default')\n",
    "inf_mode = 'merge'\n",
    "rate = 0.1\n",
    "save = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has two spatio temporal blocks and each block has two gated temporal convolutional layers and one spatial convolutional layer in between so we have totaly six layers and we should determine the size of channel for these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [[1, 32, 64], [64, 32, 128]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have a file which defines the graph we want to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228, 228])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = pd.read_csv(\"PeMSD7_W_228.csv\", header=None)\n",
    "W_tensor = torch.tensor(W.values)\n",
    "W_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation 10 on original papaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_matrix(W, sigma2=0.1, epsilon=0.5, scaling=True):\n",
    "    '''\n",
    "    Weight matrix function.\n",
    "    :param W: tensor, the adjacency matrix of the graph.\n",
    "    :param sigma2: float, scalar of matrix W.\n",
    "    :param epsilon: float, thresholds to control the sparsity of matrix W.\n",
    "    :param scaling: bool, whether applies numerical scaling on W.\n",
    "    :return: np.ndarray, [n_route, n_route].\n",
    "    '''\n",
    "    # check whether W is a 0/1 matrix.\n",
    "    if set(torch.unique(W)) == {0, 1}:\n",
    "        print('The input graph is a 0/1 matrix; set \"scaling\" to False.')\n",
    "        scaling = False\n",
    "\n",
    "    if scaling:\n",
    "        n = W.shape[0]\n",
    "        W = W / 10000. # WHY\n",
    "        W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
    "        # refer to Eq.10\n",
    "        a = torch.exp(-W2 / sigma2)\n",
    "        a[a >= epsilon] = 0\n",
    "        \n",
    "        return a * W_mask\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 1.4279e-89, 1.0224e-88,  ..., 4.9829e-01, 4.9897e-01,\n",
      "        4.9999e-01], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tmp = weight_matrix(W_tensor)\n",
    "print(torch.unique(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell I want to calculate normalized laplacian.<br/>\n",
    "I calculate it using \\(L=I - D^(-1/2) W D^(-1/2)\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_laplacian(W):\n",
    "    '''\n",
    "    Scaled graph Laplacian function.\n",
    "    :param W: np.ndarray, [n_route, n_route], weighted adjacency matrix of G.\n",
    "    :return: np.matrix, [n_route, n_route].\n",
    "    '''\n",
    "    # d ->  diagonal degree matrix\n",
    "    n, d = np.shape(W)[0], torch.sum(W, axis=1)\n",
    "    I = torch.eye(n)\n",
    "    \n",
    "    # d^(-1/2)\n",
    "    d = torch.pow(d, -1/2)\n",
    "    # make d diagonal\n",
    "    d = torch.diag(d)\n",
    "\n",
    "    dw = torch.matmul(d, W)\n",
    "    dwd = torch.matmul(dw, d)\n",
    "    \n",
    "    L = I - dwd\n",
    "    \n",
    "    # lambda_max \\approx 2.0, the largest eigenvalues of L.\n",
    "    lambdas, _ = torch.eig(L)\n",
    "    lambdas = lambdas[:, 0]\n",
    "    lambda_max = torch.max(lambdas)\n",
    "\n",
    "    return 2 * L / lambda_max - I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = scaled_laplacian(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7208, -0.1258, -0.1659, -0.1780, -0.2509, -0.2819],\n",
      "        [-0.1258,  0.7208, -0.2224, -0.2863, -0.3027, -0.3239],\n",
      "        [-0.1659, -0.2224,  0.7208, -0.3460, -0.3548, -0.3702],\n",
      "        [-0.1780, -0.2863, -0.3460,  0.3665, -0.3567, -0.3665],\n",
      "        [-0.2509, -0.3027, -0.3548, -0.3567,  0.3409, -0.3874],\n",
      "        [-0.2819, -0.3239, -0.3702, -0.3665, -0.3874,  0.3269]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([[0, 2, 3, 4, 6, 7], [2, 0, 5, 8, 9, 10], [3, 5, 0, 11, 12, 13], \n",
    "                  [4, 8, 11, 14, 15, 16], [6, 9, 12, 15, 17, 18], [7, 10, 13, 16, 18, 19]], dtype=float)\n",
    "T = scaled_laplacian(T)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chebyshev polynomials approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cheb_poly_approx(L, Ks, n):\n",
    "    '''\n",
    "    Chebyshev polynomials approximation function.\n",
    "    :param L: np.matrix, [n_route, n_route], graph Laplacian.\n",
    "    :param Ks: int, kernel size of spatial convolution.\n",
    "    :param n: int, number of routes / size of graph.\n",
    "    :return: np.ndarray, [n_route, Ks*n_route].\n",
    "    '''\n",
    "    L0, L1 = np.identity(n), np.copy(L)\n",
    "\n",
    "    if Ks > 1:\n",
    "        L_list = [np.copy(L0), np.copy(L1)]\n",
    "        for i in range(Ks - 2):\n",
    "#             print(\"L0\")\n",
    "#             print(L0)\n",
    "#             print(\"L1\")\n",
    "#             print(L1)\n",
    "#             print(\"L\")\n",
    "#             print(L)\n",
    "            Ln = 2 * L * L1 - L0\n",
    "#             print(\"Ln\")\n",
    "#             print(Ln)\n",
    "            L_list.append(np.copy(Ln))\n",
    "            L0, L1 = np.copy(L1), np.copy(Ln)\n",
    "        # L_lsit [Ks, n*n], Lk [n, Ks*n]\n",
    "        return np.concatenate(L_list, axis=-1)\n",
    "    elif Ks == 1:\n",
    "        return np.asarray(L0)\n",
    "    else:\n",
    "        raise ValueError(f'ERROR: the size of spatial kernel must be greater than 1, but received \"{Ks}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approximation method: 1st approx - first_approx(W, n).\n",
    "Lk = cheb_poly_approx(L, ks, n_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[71.1000, 66.0000, 64.6000,  ..., 69.3000, 67.7000, 68.9000],\n",
       "        [68.1000, 66.8000, 61.7000,  ..., 67.7000, 68.8000, 68.8000],\n",
       "        [68.0000, 64.3000, 66.6000,  ..., 70.2000, 69.1000, 68.7000],\n",
       "        ...,\n",
       "        [68.9000, 37.9000, 68.8000,  ..., 68.7000, 67.5000, 19.7000],\n",
       "        [69.2000, 37.8000, 68.7000,  ..., 67.7000, 67.4000, 19.5000],\n",
       "        [68.6000, 52.9000, 68.6000,  ..., 68.1000, 68.5000, 19.1000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = pd.read_csv(\"PeMSD7_V_228.csv\", header=None)\n",
    "data_file_tensor = torch.tensor(data_file.values)\n",
    "data_file_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_val, n_test = 34, 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_gen(len_seq, data_seq, offset, n_frame, n_route, day_slot, C_0=1):\n",
    "    '''\n",
    "    Generate data in the form of standard sequence unit.\n",
    "    :param len_seq: int, the length of target date sequence.  is the number of days\n",
    "    :param data_seq: np.ndarray, source data / time-series.\n",
    "    :param offset:  int, the starting index of different dataset type.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :param C_0: int, the size of input channel.\n",
    "    :return: np.ndarray, [len_seq, , C_0, n_frame, n_route].\n",
    "    '''\n",
    "    # in this example time step is 5 min so a day which is 24 hours will be 288 time steps (day_slot=288) \n",
    "    # and n_frame is 21 so we will have 288 - 21 + 1 = 268 (n_slot=268)\n",
    "    n_slot = day_slot - n_frame + 1\n",
    "\n",
    "    tmp_seq = torch.zeros((len_seq * n_slot, C_0, n_frame, n_route))\n",
    "    for i in range(len_seq):\n",
    "        for j in range(n_slot):\n",
    "            sta = (i + offset) * day_slot + j\n",
    "            end = sta + n_frame\n",
    "            tmp_seq[i * n_slot + j, :, :, :] = torch.reshape(data_seq[sta:end, :], [C_0, n_frame, n_route])\n",
    "    return tmp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    '''\n",
    "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
    "    where z is the z-score, X is the value of the element,\n",
    "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
    "    :param x: np.ndarray, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: np.ndarray, z-score normalized array.\n",
    "    '''\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datasett(object):\n",
    "    def __init__(self, data, stats):\n",
    "        self.__data = data\n",
    "        self.mean = stats['mean']\n",
    "        self.std = stats['std']\n",
    "\n",
    "    def get_data(self, type):\n",
    "        return self.__data[type]\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {'mean': self.mean, 'std': self.std}\n",
    "\n",
    "    def get_len(self, type):\n",
    "        return len(self.__data[type])\n",
    "\n",
    "    def z_inverse(self, type):\n",
    "        return self.__data[type] * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data_seq, data_config, n_route, n_frame=21, day_slot=288):\n",
    "    '''\n",
    "    Source file load and dataset generation.\n",
    "    :param file_path: str, the file path of data source.\n",
    "    :param data_config: tuple, the configs of dataset in train, validation, test.\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :return: dict, dataset that contains training, validation and test with stats.\n",
    "    '''\n",
    "    n_train, n_val, n_test = data_config\n",
    "    # generate training, validation and test data\n",
    "#     data_seq = data.values\n",
    "\n",
    "    seq_train = seq_gen(n_train, data_seq, 0, n_frame, n_route, day_slot)\n",
    "    seq_val = seq_gen(n_val, data_seq, n_train, n_frame, n_route, day_slot)\n",
    "    seq_test = seq_gen(n_test, data_seq, n_train + n_val, n_frame, n_route, day_slot)\n",
    "\n",
    "    # x_stats: dict, the stats for the train dataset, including the value of mean and standard deviation.\n",
    "    x_stats = {'mean': torch.mean(seq_train), 'std': torch.std(seq_train)}\n",
    "    print(x_stats)\n",
    "\n",
    "    # x_train, x_val, x_test: np.array, [sample_size, n_frame, n_route, channel_size].\n",
    "    x_train = z_score(seq_train, x_stats['mean'], x_stats['std'])\n",
    "    x_val = z_score(seq_val, x_stats['mean'], x_stats['std'])\n",
    "    x_test = z_score(seq_test, x_stats['mean'], x_stats['std'])\n",
    "\n",
    "    x_data = {'train': x_train, 'val': x_val, 'test': x_test}\n",
    "    dataset = Datasett(x_data, x_stats)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': tensor(58.4998), 'std': tensor(13.7286)}\n"
     ]
    }
   ],
   "source": [
    "PeMS = data_gen(data_file_tensor, (n_train, n_val, n_test), n_route, n_hist + n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_conv_layer(x, Kt, c_in, c_out, act_func='relu'):\n",
    "    '''\n",
    "    Temporal convolution layer.\n",
    "    :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "    :param Kt: int, kernel size of temporal convolution.\n",
    "    :param c_in: int, size of input channel.\n",
    "    :param c_out: int, size of output channel.\n",
    "    :param act_func: str, activation function.\n",
    "    :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "    '''\n",
    "\n",
    "    _, _, T, n = x.size()\n",
    "\n",
    "    if c_in > c_out:\n",
    "#       tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(w_input))\n",
    "#       PyTorch does not support same padding the way Keras does\n",
    "#       padding='SAME'\n",
    "        x_input = torch.nn.Conv2d(c_in, c_out, (1, 1), stride=[1, 1])(x)\n",
    "    elif c_in < c_out:\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], c_out - c_in, T, n])], axis=1)\n",
    "    else:\n",
    "        x_input = x\n",
    "        \n",
    "    # keep the original input for residual connection.\n",
    "    x_input = x_input[:, :, Kt - 1:T, :]\n",
    "        \n",
    "    if act_func == 'GLU':\n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = torch.nn.Conv2d(c_in, 2 * c_out, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:c_out, :, :] + x_input)\n",
    "        q = x_conv[:, -c_out:, :, :]\n",
    "\n",
    "        return p * torch.nn.Sigmoid()(q)\n",
    "    else:\n",
    "        x_conv = torch.nn.Conv2d(c_in, c_out, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])(x)\n",
    "#         tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "        if act_func == 'linear':\n",
    "            return x_conv\n",
    "        elif act_func == 'sigmoid':\n",
    "            return torch.nn.Sigmoid()(x_conv)\n",
    "        elif act_func == 'relu':\n",
    "            return torch.nn.ReLU()(x_conv + x_input)\n",
    "        else:\n",
    "            raise ValueError(f'ERROR: activation function \"{act_func}\" is not defined.')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gconv(x, theta, Ks, c_in, c_out, Lk):\n",
    "    '''\n",
    "    Spectral-based graph convolution function.\n",
    "    :param x: tensor, [batch_size, c_in, n_route].\n",
    "    :param theta: tensor, [Ks*c_in, c_out], trainable kernel parameters.\n",
    "    :param Ks: int, kernel size of graph convolution.\n",
    "    :param c_in: int, size of input channel.\n",
    "    :param c_out: int, size of output channel.\n",
    "    :return: tensor, [batch_size, n_route, c_out].\n",
    "    '''\n",
    "    # graph kernel: tensor, [n_route, Ks*n_route]\n",
    "    kernel = Lk\n",
    "    n = kernel.shape[0]\n",
    "    # x -> [batch_size, c_in, n_route] -> [batch_size*c_in, n_route]\n",
    "    x_tmp = torch.reshape(x, [-1, n])\n",
    "    # x_mul = x_tmp * ker -> [batch_size*c_in, Ks*n_route] -> [batch_size, c_in, Ks, n_route]\n",
    "    x_mul = torch.reshape(torch.matmul(x_tmp, torch.Tensor(kernel)), [-1, c_in, Ks, n])\n",
    "    # x_ker -> [batch_size, n_route, c_in, K_s] -> [batch_size*n_route, c_in*Ks]\n",
    "    x_ker = torch.reshape(torch.transpose(torch.transpose(x_mul, 1, 3), 2, 3), [-1, c_in * Ks])\n",
    "    # x_gconv -> [batch_size*n_route, c_out] -> [batch_size, n_route, c_out]\n",
    "    x_gconv = torch.reshape(torch.matmul(x_ker, theta), [-1, n, c_out])\n",
    "    # [batch_size, n_route, c_out] -> [batch_size, c_out, n_route]\n",
    "    x_gconv = torch.transpose(x_gconv, 1, 2) # I added this line, maybe we can also reshape to [-1, c_out, n] in \n",
    "    # the previous line instead\n",
    "    return x_gconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatio_conv_layer(x, Ks, c_in, c_out, Lk):\n",
    "    '''\n",
    "    Spatial graph convolution layer.\n",
    "    :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "    :param Ks: int, kernel size of spatial convolution.\n",
    "    :param c_in: int, size of input channel.\n",
    "    :param c_out: int, size of output channel.\n",
    "    :return: tensor, [batch_size, c_out, time_step, n_route].\n",
    "    '''\n",
    "    _, _, T, n = x.size()\n",
    "\n",
    "    x_input = x\n",
    "\n",
    "    ws = torch.rand((Ks * c_in, c_out))\n",
    "#     tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(ws))\n",
    "#     variable_summaries(ws, 'theta')\n",
    "    bs = torch.zeros((c_out))\n",
    "    # x -> [batch_size, c_in, time_step, n_route] -> [batch_size, time_step, c_in, n_route]\n",
    "    # x -> [batch_size, time_step, c_in, n_route] -> [batch_size*time_step, c_in, n_route]\n",
    "    # x -> [batch_size*time_step, c_in, n_route] -> [batch_size*time_step, c_out, n_route]\n",
    "    x_gconv = gconv(torch.reshape(torch.transpose(x, 1, 2), [-1, c_in, n]), ws, Ks, c_in, c_out, Lk) # + bs\n",
    "    # [batch_size*time_step, c_out, n_route] -> [batch_size, time_step, c_out, n_route]\n",
    "    # [batch_size, time_step, c_out, n_route] -> [batch_size, c_out, time_step, n_route]\n",
    "    x_gc = torch.transpose(torch.reshape(x_gconv, [-1, T, c_out, n]), 1, 2)\n",
    "    return torch.nn.ReLU()(x_gc[:, 0:c_out, :, :] + x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_con_layer(x, n, channel):\n",
    "    '''\n",
    "    Fully connected layer: maps multi-channels to one.\n",
    "    :param x: tensor, [batch_size, channel, 1, n_route].\n",
    "    :param n: int, number of route / size of graph.\n",
    "    :param channel: channel size of input x.\n",
    "    :return: tensor, [batch_size, 1, n_route, 1].\n",
    "    '''\n",
    "#     tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(w))\n",
    "#     PyTorch does not support same padding the way Keras does\n",
    "#     padding='SAME'\n",
    "    return torch.nn.Conv2d(channel, 1, (1, 1), stride=[1, 1], dilation=[1, 1])(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(x):\n",
    "    '''\n",
    "    Layer normalization function.\n",
    "    :param x: tensor, [batch_size, channel, time_step, n_route].\n",
    "    :return: tensor, [batch_size, channel, time_step, n_route].\n",
    "    '''\n",
    "    _, C, _, N = x.size()\n",
    "    mu, sigma = torch.mean(x, dim=[2, 3], keepdim=True), torch.var(x, dim=[2, 3], keepdim=True)\n",
    "\n",
    "    gamma = torch.ones([1, C, 1, N])\n",
    "    beta = torch.zeros([1, C, 1, N])\n",
    "    _x = (x - mu) / torch.sqrt(sigma + 1e-6) * gamma + beta\n",
    "    \n",
    "    return _x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_layer(x, T, act_func='GLU'):\n",
    "    '''\n",
    "    Output layer: temporal convolution layers attach with one fully connected layer,\n",
    "    which map outputs of the last st_conv block to a single-step prediction.\n",
    "    :param x: tensor, [batch_size, channel, time_step, n_route].\n",
    "    :param T: int, kernel size of temporal convolution.\n",
    "    :param scope: str, variable scope.\n",
    "    :param act_func: str, activation function.\n",
    "    :return: tensor, [batch_size, 1, n_route, 1].\n",
    "    '''\n",
    "    _, channel, _, n = x.size()\n",
    "\n",
    "    # maps multi-steps to one.\n",
    "    x_i = temporal_conv_layer(x, T, channel, channel, act_func=act_func)\n",
    "    x_ln = layer_norm(x_i)\n",
    "    print(\"x_i\")\n",
    "    print(x_i.size())\n",
    "    x_o = temporal_conv_layer(x_ln, 1, channel, channel, act_func='sigmoid')\n",
    "    # maps multi-channels to one.\n",
    "    x_fc = fully_con_layer(x_o, n, channel)\n",
    "    return x_fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(inputs, n_his, Ks, Kt, blocks, rate, Lk):\n",
    "    '''\n",
    "    Build the base model.\n",
    "    :param inputs: placeholder.\n",
    "    :param n_his: int, size of historical records for training.\n",
    "    :param Ks: int, kernel size of spatial convolution.\n",
    "    :param Kt: int, kernel size of temporal convolution.\n",
    "    :param blocks: list, channel configs of st_conv blocks.\n",
    "    :param keep_prob: placeholder.\n",
    "    '''\n",
    "    x = inputs[:, 0:n_his, :, :]\n",
    "\n",
    "    # Ko>0: kernel size of temporal convolution in the output layer.\n",
    "    Ko = n_his\n",
    "    # ST-Block\n",
    "    for i, channels in enumerate(blocks):\n",
    "        x = st_conv_block(x, Ks, Kt, channels, i, rate, Lk, act_func='GLU')\n",
    "        Ko -= 2 * (Kt - 1)\n",
    "\n",
    "    # Output Layer\n",
    "    if Ko > 1:\n",
    "        y = output_layer(x, Ko)\n",
    "    else:\n",
    "        raise ValueError(f'ERROR: kernel size Ko must be greater than 1, but received \"{Ko}\".')\n",
    "\n",
    "#     tf.add_to_collection(name='copy_loss',\n",
    "#                          value=tf.nn.l2_loss(inputs[:, n_his - 1:n_his, :, :] - inputs[:, n_his:n_his + 1, :, :]))\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    train_loss = loss_fn(y, inputs[:, :, n_his + 1:n_his + 2, :])\n",
    "    single_pred = y[:, 0, :, :]\n",
    "#     tf.add_to_collection(name='y_pred', value=single_pred)\n",
    "    return train_loss, single_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST_Network(torch.nn.Module):\n",
    "    def __init__(self, n_his, Ks, Kt, blocks, rate, Lk):\n",
    "        '''\n",
    "        Build the base model.\n",
    "        :param n_his: int, size of historical records for training.\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param blocks: list, channel configs of st_conv blocks.\n",
    "        :param rate: the rate of dropout.\n",
    "        '''\n",
    "        super(ST_Network, self).__init__()\n",
    "        self.n_his = n_his\n",
    "        self.Ks = Ks\n",
    "        self.Kt = Kt\n",
    "        self.blocks = blocks\n",
    "        self.rate = rate\n",
    "        self.Lk = Lk\n",
    "        self.Conv2DBlock1Temporal1GLU = torch.nn.Conv2d(1, 2 * 32, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidBlock1Temporal1 = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.ReLUBlock1Spatio = torch.nn.ReLU()\n",
    "        \n",
    "        self.Conv2DBlock1Temporal2ReLU = torch.nn.Conv2d(32, 64, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.ReLUBlock1Temporal2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.DropoutBlock1 = torch.nn.Dropout(p=rate)\n",
    "        \n",
    "        self.Conv2DBlock2Temporal1 = torch.nn.Conv2d(64, 32, (1, 1), stride=[1, 1])\n",
    "        self.Conv2DBlock2Temporal1GLU = torch.nn.Conv2d(64, 2 * 32, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidBlock2Temporal1 = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.ReLUBlock2Spatio = torch.nn.ReLU()\n",
    "    \n",
    "        self.Conv2DBlock2Temporal2ReLU = torch.nn.Conv2d(32, 128, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.ReLUBlock2Temporal2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.DropoutBlock2 = torch.nn.Dropout(p=rate)\n",
    "        \n",
    "        self.Conv2DOutputTemporal1GLU = torch.nn.Conv2d(128, 2 * 128, (self.Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidOutputTemporal1 = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        :param inputs: placeholder.\n",
    "        '''\n",
    "        x = inputs[:, 0:self.n_his, :, :]\n",
    "        # Ko>0: kernel size of temporal convolution in the output layer.\n",
    "        Ko = self.n_his\n",
    "        \n",
    "        # ST-Block\n",
    "        x = self.st_conv_block1(x, self.blocks[0], act_func='GLU')\n",
    "        Ko -= 2 * (self.Kt - 1)\n",
    "        \n",
    "        x = self.st_conv_block2(x, self.blocks[1], act_func='GLU')\n",
    "        Ko -= 2 * (self.Kt - 1)\n",
    "            \n",
    "\n",
    "        # Output Layer\n",
    "        if Ko > 1:\n",
    "            y = self.output_layer(x, Ko)\n",
    "        else:\n",
    "            raise ValueError(f'ERROR: kernel size Ko must be greater than 1, but received \"{Ko}\".')\n",
    "\n",
    "        #     tf.add_to_collection(name='copy_loss',\n",
    "        #                          value=tf.nn.l2_loss(y - inputs[:, n_his:n_his + 1, :, :]))\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#         train_loss = loss_fn(y, inputs[:, :, n_his:n_his + 1, :])\n",
    "#         single_pred = y[:, 0, :, :]\n",
    "        #     tf.add_to_collection(name='y_pred', value=single_pred)\n",
    "#         return train_loss, single_pred\n",
    "        return y\n",
    "\n",
    "    def st_conv_block1(self, x, channels, act_func='GLU'):\n",
    "        '''\n",
    "        Spatio-temporal convolutional block, which contains two temporal gated convolution layers\n",
    "        and one spatial graph convolution layer in the middle.\n",
    "        :param x: tensor, batch_size, time_step, n_route, c_in].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param channels: list, channel configs of a single st_conv block.\n",
    "        :param scope: str, variable scope.\n",
    "        :param keep_prob: placeholder, prob of dropout.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, time_step, n_route, c_out].\n",
    "        '''\n",
    "        print(x.size())\n",
    "#         c_si, c_t, c_oo = channels\n",
    "        \n",
    "        x_s = self.block1Temporal1(x)\n",
    "        x_t = self.block1Spatio(x_s)\n",
    "        x_o = self.block1Temporal2(x_t)\n",
    "    #     x_ln = layer_norm(x_o, f'layer_norm_{scope}')\n",
    "    \n",
    "        return self.DropoutBlock1(x_o)\n",
    "    \n",
    "    def block1Temporal1(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 32 - 1, T, n])], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DBlock1Temporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:32, :, :] + x_input)\n",
    "        q = x_conv[:, -32:, :, :]\n",
    "\n",
    "        return p * self.SigmoidBlock1Temporal1(q)\n",
    "    \n",
    "    def block1Spatio(self, x):\n",
    "        '''\n",
    "        Spatial graph convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :return: tensor, [batch_size, c_out, time_step, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        x_input = x\n",
    "\n",
    "        ws = torch.rand((self.Ks * 32, 32))\n",
    "    #     tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(ws))\n",
    "    #     variable_summaries(ws, 'theta')\n",
    "        bs = torch.zeros((32))\n",
    "        # x -> [batch_size, c_in, time_step, n_route] -> [batch_size, time_step, c_in, n_route]\n",
    "        # x -> [batch_size, time_step, c_in, n_route] -> [batch_size*time_step, c_in, n_route]\n",
    "        # x -> [batch_size*time_step, c_in, n_route] -> [batch_size*time_step, c_out, n_route]\n",
    "        x_gconv = gconv(torch.reshape(torch.transpose(x, 1, 2), [-1, 32, n]), ws, self.Ks, 32, 32, self.Lk) # + bs\n",
    "        # [batch_size*time_step, c_out, n_route] -> [batch_size, time_step, c_out, n_route]\n",
    "        # [batch_size, time_step, c_out, n_route] -> [batch_size, c_out, time_step, n_route]\n",
    "        x_gc = torch.transpose(torch.reshape(x_gconv, [-1, T, 32, n]), 1, 2)\n",
    "        \n",
    "        return self.ReLUBlock1Spatio(x_gc[:, 0:32, :, :] + x_input)\n",
    "    \n",
    "    def block1Temporal2(self, x, act_func='relu'):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 64 - 32, T, n])], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        x_conv = self.Conv2DBlock1Temporal2ReLU(x)\n",
    "#         tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "\n",
    "        return self.ReLUBlock1Temporal2(x_conv + x_input)\n",
    "\n",
    "    def st_conv_block2(self, x, channels, act_func='GLU'):\n",
    "        '''\n",
    "        Spatio-temporal convolutional block, which contains two temporal gated convolution layers\n",
    "        and one spatial graph convolution layer in the middle.\n",
    "        :param x: tensor, batch_size, time_step, n_route, c_in].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param channels: list, channel configs of a single st_conv block.\n",
    "        :param scope: str, variable scope.\n",
    "        :param keep_prob: placeholder, prob of dropout.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, time_step, n_route, c_out].\n",
    "        '''\n",
    "#         c_si, c_t, c_oo = channels\n",
    "        \n",
    "        print(\"st_conv_block2 x.size()\")\n",
    "        print(x.size())\n",
    "        x_s = self.block2Temporal1(x)\n",
    "        x_t = self.block2Spatio(x_s)\n",
    "        x_o = self.block2Temporal2(x_t)\n",
    "    #     x_ln = layer_norm(x_o, f'layer_norm_{scope}')\n",
    "    \n",
    "        return self.DropoutBlock2(x_o)\n",
    "    \n",
    "    def block2Temporal1(self, x, act_func='relu'):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "#       tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(w_input))\n",
    "#       PyTorch does not support same padding the way Keras does\n",
    "#       padding='SAME'\n",
    "        x_input = self.Conv2DBlock2Temporal1(x)\n",
    "\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DBlock2Temporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:32, :, :] + x_input)\n",
    "        q = x_conv[:, -32:, :, :]\n",
    "\n",
    "        return p * self.SigmoidBlock2Temporal1(q)  \n",
    "    \n",
    "    def block2Spatio(self, x):\n",
    "        '''\n",
    "        Spatial graph convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :return: tensor, [batch_size, c_out, time_step, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        x_input = x\n",
    "\n",
    "        ws = torch.rand((self.Ks * 32, 32))\n",
    "    #     tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(ws))\n",
    "    #     variable_summaries(ws, 'theta')\n",
    "        bs = torch.zeros((32))\n",
    "        # x -> [batch_size, c_in, time_step, n_route] -> [batch_size, time_step, c_in, n_route]\n",
    "        # x -> [batch_size, time_step, c_in, n_route] -> [batch_size*time_step, c_in, n_route]\n",
    "        # x -> [batch_size*time_step, c_in, n_route] -> [batch_size*time_step, c_out, n_route]\n",
    "        x_gconv = gconv(torch.reshape(torch.transpose(x, 1, 2), [-1, 32, n]), ws, self.Ks, 32, 32, self.Lk) # + bs\n",
    "        # [batch_size*time_step, c_out, n_route] -> [batch_size, time_step, c_out, n_route]\n",
    "        # [batch_size, time_step, c_out, n_route] -> [batch_size, c_out, time_step, n_route]\n",
    "        x_gc = torch.transpose(torch.reshape(x_gconv, [-1, T, 32, n]), 1, 2)\n",
    "        \n",
    "        return self.ReLUBlock2Spatio(x_gc[:, 0:32, :, :] + x_input)\n",
    "        \n",
    "    def block2Temporal2(self, x, act_func='relu'):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "        \n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 128 - 32, T, n])], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        x_conv = self.Conv2DBlock2Temporal2ReLU(x)\n",
    "#         tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "\n",
    "        return self.ReLUBlock2Temporal2(x_conv + x_input)\n",
    "\n",
    "    def output_layer(self, x, T, act_func='GLU'):\n",
    "        '''\n",
    "        Output layer: temporal convolution layers attach with one fully connected layer,\n",
    "        which map outputs of the last st_conv block to a single-step prediction.\n",
    "        :param x: tensor, [batch_size, channel, time_step, n_route].\n",
    "        :param T: int, kernel size of temporal convolution.\n",
    "        :param scope: str, variable scope.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, 1, n_route, 1].\n",
    "        '''\n",
    "        _, channel, _, n = x.size()\n",
    "        print(\"output layer channel\")\n",
    "        print(channel)\n",
    "\n",
    "        # maps multi-steps to one.\n",
    "        x_i = self.output_layer_temp1_GLU(x, act_func=act_func)\n",
    "        x_ln = layer_norm(x_i)\n",
    "        print(\"x_i\")\n",
    "        print(x_i.size())\n",
    "        ######################## here\n",
    "        x_o = temporal_conv_layer(x_ln, 1, channel, channel, act_func='sigmoid')\n",
    "        # maps multi-channels to one.\n",
    "        x_fc = fully_con_layer(x_o, n, channel)\n",
    "        return x_fc\n",
    "    \n",
    "    def output_layer_temp1_GLU(self, x, act_func='relu'):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        x_input = x\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DOutputTemporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:128, :, :] + x_input)\n",
    "        q = x_conv[:, -128:, :, :]\n",
    "\n",
    "        return p * self.SigmoidOutputTemporal1(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ST_Network(n_hist, ks, kt, blocks, rate, Lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, model, epoch, n_hist):\n",
    "    # define the optimization\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # torch.optim.Adam(lr, weight_decay=0.01).minimize(train_loss)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    # enumerate epochs\n",
    "            \n",
    "    for epoch in range(epoch):\n",
    "        start_time = time.time()\n",
    "        data_loader = DataLoader(inputs.get_data('train'),\n",
    "                                 batch_size=batch_size,\n",
    "                                 drop_last=True)\n",
    "        # gen_batch(inputs.get_data('train'), batch_size, dynamic_batch=True, shuffle=True)\n",
    "        # enumerate mini batches\n",
    "        j = 0\n",
    "        for x_batch in iter(data_loader):\n",
    "            x = x_batch[:, 0:n_hist + 1, :, :]\n",
    "            rate = 0\n",
    "            # clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Define model loss\n",
    "            # compute the model output\n",
    "            yhat = model(x)\n",
    "            # calculate loss\n",
    "            print(type(yhat))\n",
    "            print(yhat.size())\n",
    "            print(\"x_batch[:, :, n_hist-2:, :]\")\n",
    "            print(x_batch[:, :, n_hist-2:, :].size())\n",
    "            # todo the dimention of yhat is wrong. its dimention 2 value should be 9 not 10\n",
    "            loss = criterion(yhat, x_batch[:, :, n_hist-2:, :])\n",
    "            print(loss)\n",
    "            # credit assignment\n",
    "            loss.backward()\n",
    "            # update model weights\n",
    "            optimizer.step()  \n",
    "            j += 1\n",
    "        \n",
    "        print(f'Epoch {i:2d} Training Time {time.time() - start_time:.3f}s')\n",
    "\n",
    "        start_time = time.time()\n",
    "#         min_va_val, min_val = \\\n",
    "#                 model_inference(sess, pred, inputs, batch_size, n_his, n_pred, step_idx, min_va_val, min_val)\n",
    "\n",
    "            \n",
    "#         loss = loss_fn(predictions, t)\n",
    "#       train_op.step()\n",
    "#         for ix in tmp_idx:\n",
    "#             va, te = min_va_val[ix - 2:ix + 1], min_val[ix - 2:ix + 1]\n",
    "#             print(f'Time Step {ix + 1}: '\n",
    "#                     f'MAPE {va[0]:7.3%}, {te[0]:7.3%}; '\n",
    "#                     f'MAE  {va[1]:4.3f}, {te[1]:4.3f}; '\n",
    "#                     f'RMSE {va[2]:6.3f}, {te[2]:6.3f}.')\n",
    "#         print(f'Epoch {i:2d} Inference Time {time.time() - start_time:.3f}s')\n",
    "\n",
    "        if (i + 1) % save == 0:\n",
    "            torch.save(model.state_dict(), \"kopol\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1, 21, 228])\n",
      "st_conv_block2 x.size()\n",
      "torch.Size([50, 64, 17, 228])\n",
      "output layer channel\n",
      "128\n",
      "x_i\n",
      "torch.Size([50, 128, 11, 228])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 1, 11, 228])\n",
      "x_batch[:, :, n_hist-2:, :]\n",
      "torch.Size([50, 1, 11, 228])\n",
      "tensor(0.1544, grad_fn=<MseLossBackward>)\n",
      "torch.Size([50, 1, 21, 228])\n",
      "st_conv_block2 x.size()\n",
      "torch.Size([50, 64, 17, 228])\n",
      "output layer channel\n",
      "128\n",
      "x_i\n",
      "torch.Size([50, 128, 11, 228])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 1, 11, 228])\n",
      "x_batch[:, :, n_hist-2:, :]\n",
      "torch.Size([50, 1, 11, 228])\n",
      "tensor(1.3553, grad_fn=<MseLossBackward>)\n",
      "torch.Size([50, 1, 21, 228])\n",
      "st_conv_block2 x.size()\n",
      "torch.Size([50, 64, 17, 228])\n",
      "output layer channel\n",
      "128\n",
      "x_i\n",
      "torch.Size([50, 128, 11, 228])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([50, 1, 11, 228])\n",
      "x_batch[:, :, n_hist-2:, :]\n",
      "torch.Size([50, 1, 11, 228])\n",
      "tensor(0.3859, grad_fn=<MseLossBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-10bfc83025bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPeMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# todo the problem was model.parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-7b635354ebb1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inputs, model, epoch, n_hist)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;31m# credit assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;31m# update model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(PeMS, model, epoch, n_hist)\n",
    "# todo the problem was model.parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(inputs, blocks, n_route, n_hist, n_pred, Ks, Kt, batch_size, epoch, inf_mode, opt, rate, Lk, sum_path='./output/tensorboard'):\n",
    "    '''\n",
    "    Train the base model.\n",
    "    :param inputs: instance of class Dataset, data source for training.\n",
    "    :param blocks: list, channel configs of st_conv blocks.\n",
    "    '''\n",
    "    \n",
    "    # Placeholder for model training\n",
    "#     x = (tf.float32, [None, n_his + 1, n, 1], name='data_input')\n",
    "\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    len_train = inputs.get_len('train')\n",
    "    if len_train % batch_size == 0:\n",
    "        epoch_step = len_train / batch_size\n",
    "    else:\n",
    "        epoch_step = int(len_train / batch_size) + 1\n",
    "        \n",
    "    writer.add_scalar('learning_rate', lr)\n",
    "#     step_op = tf.assign_add(global_steps, 1)\n",
    "    \n",
    "#     if opt == torch.optim.RMSprop:\n",
    "#         train_op = torch.optim.RMSprop(lr)\n",
    "#     elif opt == 'ADAM':\n",
    "#         train_op = torch.optim.Adam(lr, weight_decay=0.01).minimize(train_loss)\n",
    "#     else:\n",
    "#         raise ValueError(f'ERROR: optimizer \"{opt}\" is not defined.')\n",
    "\n",
    "#     merged = tf.summary.merge_all()\n",
    "\n",
    "#     writer = tf.summary.FileWriter(pjoin(sum_path, 'train'), sess.graph)\n",
    "    if inf_mode == 'merge':\n",
    "        # for inference mode 'merge', the type of step index is np.ndarray.\n",
    "        step_idx = tmp_idx = np.arange(3, n_pred + 1, 3) - 1\n",
    "        min_val = min_va_val = np.array([4e1, 1e5, 1e5] * len(step_idx))\n",
    "    else:\n",
    "        raise ValueError(f'ERROR: test mode \"{inf_mode}\" is not defined.')\n",
    "\n",
    "#     train_op.zero_grad()\n",
    "    for i in range(epoch):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        data_loader = DataLoader(inputs.get_data('train'),\n",
    "                     batch_size=batch_size,\n",
    "                     drop_last=True)\n",
    "# gen_batch(inputs.get_data('train'), batch_size, dynamic_batch=True, shuffle=True)\n",
    "\n",
    "        j = 0\n",
    "        for x_batch in iter(data_loader):\n",
    "            x = x_batch[:, 0:n_hist + 1, :, :]\n",
    "            rate = 0\n",
    "            \n",
    "            # Define model loss\n",
    "            train_loss, pred = build_model(x, n_hist, Ks, Kt, blocks, rate, Lk)\n",
    "            writer.add_scalar('train_loss', train_loss)\n",
    "#             copy_loss = tf.add_n(tf.get_collection('copy_loss'))\n",
    "#             writer.add_scalar('copy_loss', copy_loss)\n",
    "    \n",
    "#             summary, _ = sess.run([merged, train_op])\n",
    "#             writer.add_summary(summary, i * epoch_step + j)\n",
    "#             if j % 50 == 0:\n",
    "#                 loss_value = sess.run([train_loss, copy_loss]\n",
    "#                 print(f'Epoch {i:2d}, Step {j:3d}: [{loss_value[0]:.3f}, {loss_value[1]:.3f}]')\n",
    "            j += 1\n",
    "        print(f'Epoch {i:2d} Training Time {time.time() - start_time:.3f}s')\n",
    "\n",
    "        start_time = time.time()\n",
    "        min_va_val, min_val = \\\n",
    "                model_inference(sess, pred, inputs, batch_size, n_his, n_pred, step_idx, min_va_val, min_val)\n",
    "\n",
    "            \n",
    "        loss = loss_fn(predictions, t)\n",
    "        loss.backward()\n",
    "#         train_op.step()\n",
    "        for ix in tmp_idx:\n",
    "            va, te = min_va_val[ix - 2:ix + 1], min_val[ix - 2:ix + 1]\n",
    "            print(f'Time Step {ix + 1}: '\n",
    "                    f'MAPE {va[0]:7.3%}, {te[0]:7.3%}; '\n",
    "                    f'MAE  {va[1]:4.3f}, {te[1]:4.3f}; '\n",
    "                    f'RMSE {va[2]:6.3f}, {te[2]:6.3f}.')\n",
    "        print(f'Epoch {i:2d} Inference Time {time.time() - start_time:.3f}s')\n",
    "\n",
    "        if (i + 1) % save == 0:\n",
    "            torch.save()\n",
    "    writer.close()\n",
    "    print('Training model finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(PeMS, blocks, n_route, n_hist, n_pred, ks, kt, batch_size, epoch, inf_mode, opt, rate, Lk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(inputs, batch_size, n_his, n_pred, inf_mode, load_path='./output/models/'):\n",
    "    '''\n",
    "    Load and test saved model from the checkpoint.\n",
    "    :param inputs: instance of class Dataset, data source for test.\n",
    "    :param batch_size: int, the size of batch.\n",
    "    :param n_his: int, the length of historical records for training.\n",
    "    :param n_pred: int, the length of prediction.\n",
    "    :param inf_mode: str, test mode - 'merge / multi-step test' or 'separate / single-step test'.\n",
    "    :param load_path: str, the path of loaded model.\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "    model_path = tf.train.get_checkpoint_state(load_path).model_checkpoint_path\n",
    "\n",
    "    test_graph = tf.Graph()\n",
    "\n",
    "    with test_graph.as_default():\n",
    "        saver = tf.train.import_meta_graph(pjoin(f'{model_path}.meta'))\n",
    "\n",
    "    with tf.Session(graph=test_graph) as test_sess:\n",
    "        saver.restore(test_sess, tf.train.latest_checkpoint(load_path))\n",
    "        print(f'>> Loading saved model from {model_path} ...')\n",
    "\n",
    "        pred = test_graph.get_collection('y_pred')\n",
    "\n",
    "        if inf_mode == 'sep':\n",
    "            # for inference mode 'sep', the type of step index is int.\n",
    "            step_idx = n_pred - 1\n",
    "            tmp_idx = [step_idx]\n",
    "        elif inf_mode == 'merge':\n",
    "            # for inference mode 'merge', the type of step index is np.ndarray.\n",
    "            step_idx = tmp_idx = np.arange(3, n_pred + 1, 3) - 1\n",
    "        else:\n",
    "            raise ValueError(f'ERROR: test mode \"{inf_mode}\" is not defined.')\n",
    "\n",
    "        x_test, x_stats = inputs.get_data('test'), inputs.get_stats()\n",
    "\n",
    "        y_test, len_test = multi_pred(test_sess, pred, x_test, batch_size, n_his, n_pred, step_idx)\n",
    "        evl = evaluation(x_test[0:len_test, step_idx + n_his, :, :], y_test, x_stats)\n",
    "\n",
    "        for ix in tmp_idx:\n",
    "            te = evl[ix - 2:ix + 1]\n",
    "            print(f'Time Step {ix + 1}: MAPE {te[0]:7.3%}; MAE  {te[1]:4.3f}; RMSE {te[2]:6.3f}.')\n",
    "        print(f'Model Test Time {time.time() - start_time:.3f}s')\n",
    "    print('Testing model finished!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test(PeMS, PeMS.get_len('test'), n_hist, n_pred, inf_mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

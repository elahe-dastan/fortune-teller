{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code and all my understandings and everything about magic. This is somehow my first serious work in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# TODO: make these constants arguments\n",
    "n_route = 228\n",
    "n_hist = 12\n",
    "n_pred = 9\n",
    "batch_size = 50\n",
    "epoch = 50\n",
    "# parser.add_argument('--save', type=int, default=10)\n",
    "ks = 3  # spatial convolution kernel size\n",
    "kt = 3  # temporal convolution kernel size\n",
    "lr = 1e-3\n",
    "opt = torch.optim.Adam\n",
    "# parser.add_argument('--graph', type=str, default='default')\n",
    "inf_mode = 'merge'\n",
    "rate = 0.1\n",
    "save = 10\n",
    "Ko = 4\n",
    "sch = torch.optim.lr_scheduler.ExponentialLR\n",
    "decay = 0.1\n",
    "# Ko changes with n_hist and Kt -> Ko = n_hist - 4 * Kt\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has two spatio temporal blocks and each block has two gated temporal convolutional layers and one spatial convolutional layer in between so we have totaly six layers and we should determine the size of channel for these layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [[1, 32, 64], [64, 32, 128]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should have a file which defines the graph we want to work on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([228, 228])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = pd.read_csv(\"PeMSD7_W_228.csv\", header=None)\n",
    "W_tensor = torch.tensor(W.values)\n",
    "W_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation 10 on original papaer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_matrix(W, sigma2=0.1, epsilon=0.5, scaling=True):\n",
    "    '''\n",
    "    Weight matrix function.\n",
    "    :param W: tensor, the adjacency matrix of the graph.\n",
    "    :param sigma2: float, scalar of matrix W.\n",
    "    :param epsilon: float, thresholds to control the sparsity of matrix W.\n",
    "    :param scaling: bool, whether applies numerical scaling on W.\n",
    "    :return: np.ndarray, [n_route, n_route].\n",
    "    '''\n",
    "    # check whether W is a 0/1 matrix.\n",
    "    if set(torch.unique(W)) == {0, 1}:\n",
    "        print('The input graph is a 0/1 matrix; set \"scaling\" to False.')\n",
    "        scaling = False\n",
    "\n",
    "    if scaling:\n",
    "        n = W.shape[0]\n",
    "        W = W / 10000. # WHY\n",
    "        W2, W_mask = W * W, np.ones([n, n]) - np.identity(n)\n",
    "        # refer to Eq.10\n",
    "        a = torch.exp(-W2 / sigma2)\n",
    "        a[a >= epsilon] = 0\n",
    "        \n",
    "        return a * W_mask\n",
    "    \n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 1.4279e-89, 1.0224e-88,  ..., 4.9829e-01, 4.9897e-01,\n",
      "        4.9999e-01], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tmp = weight_matrix(W_tensor)\n",
    "print(torch.unique(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21397])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(tmp).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell I want to calculate normalized laplacian.<br/>\n",
    "I calculate it using \\(L=I - D^(-1/2) W D^(-1/2)\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some how different from the researchers code needs more investigation\n",
    "\n",
    "def scaled_laplacian(W):\n",
    "    '''\n",
    "    Scaled graph Laplacian function.\n",
    "    :param W: np.ndarray, [n_route, n_route], weighted adjacency matrix of G.\n",
    "    :return: np.matrix, [n_route, n_route].\n",
    "    '''\n",
    "    # d ->  diagonal degree matrix\n",
    "    n, d = np.shape(W)[0], torch.sum(W, axis=1)\n",
    "    I = torch.eye(n)\n",
    "    \n",
    "    # d^(-1/2)\n",
    "    d = torch.pow(d, -1/2)\n",
    "    # make d diagonal\n",
    "    d = torch.diag(d)\n",
    "\n",
    "    dw = torch.matmul(d, W)\n",
    "    dwd = torch.matmul(dw, d)\n",
    "    \n",
    "    L = I - dwd\n",
    "    \n",
    "    # lambda_max \\approx 2.0, the largest eigenvalues of L.\n",
    "    lambdas, _ = torch.eig(L)\n",
    "    lambdas = lambdas[:, 0]\n",
    "    lambda_max = torch.max(lambdas)\n",
    "\n",
    "    return 2 * L / lambda_max - I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000,    inf,    inf],\n",
      "        [   inf,    inf,    inf],\n",
      "        [   inf,    inf, 0.7071]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.Tensor([[1, 0, 0], [0, 0, 0], [0, 0, 2]])\n",
    "x = torch.pow(z, -1/2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# issue if tmp has zero on the diagonal we'll hae infinity in L and be in trouble\n",
    "# https://github.com/VeritasYin/STGCN_IJCAI-18/issues/25\n",
    "# copy the code from the source code\n",
    "L = scaled_laplacian(tmp)\n",
    "print(type(L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True in torch.isinf(L):\n",
    "    print(\"sdff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.7208, -0.1258, -0.1659, -0.1780, -0.2509, -0.2819],\n",
      "        [-0.1258,  0.7208, -0.2224, -0.2863, -0.3027, -0.3239],\n",
      "        [-0.1659, -0.2224,  0.7208, -0.3460, -0.3548, -0.3702],\n",
      "        [-0.1780, -0.2863, -0.3460,  0.3665, -0.3567, -0.3665],\n",
      "        [-0.2509, -0.3027, -0.3548, -0.3567,  0.3409, -0.3874],\n",
      "        [-0.2819, -0.3239, -0.3702, -0.3665, -0.3874,  0.3269]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "T = torch.tensor([[0, 2, 3, 4, 6, 7], [2, 0, 5, 8, 9, 10], [3, 5, 0, 11, 12, 13], \n",
    "                  [4, 8, 11, 14, 15, 16], [6, 9, 12, 15, 17, 18], [7, 10, 13, 16, 18, 19]], dtype=float)\n",
    "T = scaled_laplacian(T)\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chebyshev polynomials approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually this is half of cheb poly\n",
    "def cheb_poly_approx(L, Ks, n):\n",
    "    '''\n",
    "    Chebyshev polynomials approximation function.\n",
    "    :param L: np.matrix, [n_route, n_route], graph Laplacian.\n",
    "    :param Ks: int, kernel size of spatial convolution.\n",
    "    :param n: int, number of routes / size of graph.\n",
    "    :return: np.ndarray, [n_route, Ks*n_route].\n",
    "    '''\n",
    "    L0, L1 = torch.eye(n), L.detach().clone()\n",
    "\n",
    "    if Ks > 1:\n",
    "        L_list = [L0.detach().clone(), L1.detach().clone()]\n",
    "        for i in range(Ks - 2):\n",
    "            Ln = 2 * L * L1 - L0\n",
    "            L_list.append(Ln.detach().clone())\n",
    "            L0, L1 = L1.detach().clone(), Ln.detach().clone()\n",
    "        # L_lsit [Ks, n*n], Lk [n, Ks*n]\n",
    "        return torch.cat(L_list, axis=-1)\n",
    "    elif Ks == 1:\n",
    "        return L0\n",
    "    else:\n",
    "        raise ValueError(f'ERROR: the size of spatial kernel must be greater than 1, but received \"{Ks}\".')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approximation method: 1st approx - first_approx(W, n).\n",
    "Lk = cheb_poly_approx(L, ks, n_route)\n",
    "Lk = Lk.to(device)\n",
    "Lk = Lk.type(torch.cuda.FloatTensor)\n",
    "# Lk = Lk.type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = pd.read_csv(\"PeMSD7_V_228.csv\", header=None)\n",
    "data_file_tensor = torch.tensor(data_file.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_val, n_test = 34, 5, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_gen(len_seq, data_seq, offset, n_frame, n_route, day_slot, C_0=1):\n",
    "    '''\n",
    "    Generate data in the form of standard sequence unit.\n",
    "    :param len_seq: int, the length of target date sequence.  is the number of days\n",
    "    :param data_seq: np.ndarray, source data / time-series.\n",
    "    :param offset:  int, the starting index of different dataset type.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :param C_0: int, the size of input channel.\n",
    "    :return: np.ndarray, [len_seq, , C_0, n_frame, n_route].\n",
    "    '''\n",
    "    # in this example time step is 5 min so a day which is 24 hours will be 288 time steps (day_slot=288) \n",
    "    # and n_frame is 21 so we will have 288 - 21 + 1 = 268 (n_slot=268)\n",
    "    n_slot = day_slot - n_frame + 1\n",
    "\n",
    "    tmp_seq = torch.zeros((len_seq * n_slot, C_0, n_frame, n_route))\n",
    "    for i in range(len_seq):\n",
    "        for j in range(n_slot):\n",
    "            sta = (i + offset) * day_slot + j\n",
    "            end = sta + n_frame\n",
    "            tmp_seq[i * n_slot + j, :, :, :] = torch.reshape(data_seq[sta:end, :], [C_0, n_frame, n_route])\n",
    "    return tmp_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(x, mean, std):\n",
    "    '''\n",
    "    Z-score normalization function: $z = (X - \\mu) / \\sigma $,\n",
    "    where z is the z-score, X is the value of the element,\n",
    "    $\\mu$ is the population mean, and $\\sigma$ is the standard deviation.\n",
    "    :param x: np.ndarray, input array to be normalized.\n",
    "    :param mean: float, the value of mean.\n",
    "    :param std: float, the value of standard deviation.\n",
    "    :return: np.ndarray, z-score normalized array.\n",
    "    '''\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, data, stats):\n",
    "        self.__data = data\n",
    "        self.mean = stats['mean']\n",
    "        self.std = stats['std']\n",
    "\n",
    "    def get_data(self, type):\n",
    "        return self.__data[type]\n",
    "\n",
    "    def get_stats(self):\n",
    "        return {'mean': self.mean, 'std': self.std}\n",
    "\n",
    "    def get_len(self, type):\n",
    "        return len(self.__data[type])\n",
    "\n",
    "    def z_inverse(self, type):\n",
    "        return self.__data[type] * self.std + self.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data_seq, data_config, n_route, n_frame=21, day_slot=288):\n",
    "    '''\n",
    "    Source file load and dataset generation.\n",
    "    :param file_path: str, the file path of data source.\n",
    "    :param data_config: tuple, the configs of dataset in train, validation, test.\n",
    "    :param n_route: int, the number of routes in the graph.\n",
    "    :param n_frame: int, the number of frame within a standard sequence unit,\n",
    "                         which contains n_his = 12 and n_pred = 9 (3 /15 min, 6 /30 min & 9 /45 min).\n",
    "    :param day_slot: int, the number of time slots per day, controlled by the time window (5 min as default).\n",
    "    :return: dict, dataset that contains training, validation and test with stats.\n",
    "    '''\n",
    "    n_train, n_val, n_test = data_config\n",
    "    # generate training, validation and test data\n",
    "#     data_seq = data.values\n",
    "    \n",
    "    seq_train = seq_gen(n_train, data_seq, 0, n_frame, n_route, day_slot)\n",
    "    seq_val = seq_gen(n_val, data_seq, n_train, n_frame, n_route, day_slot)\n",
    "    seq_test = seq_gen(n_test, data_seq, n_train + n_val, n_frame, n_route, day_slot)\n",
    "\n",
    "    # x_stats: dict, the stats for the train dataset, including the value of mean and standard deviation.\n",
    "    x_stats = {'mean': torch.mean(seq_train), 'std': torch.std(seq_train)}\n",
    "    print(x_stats)\n",
    "\n",
    "    # x_train, x_val, x_test: np.array, [sample_size, n_frame, n_route, channel_size].\n",
    "    x_train = z_score(seq_train, x_stats['mean'], x_stats['std'])\n",
    "    x_val = z_score(seq_val, x_stats['mean'], x_stats['std'])\n",
    "    x_test = z_score(seq_test, x_stats['mean'], x_stats['std'])\n",
    "    \n",
    "    x_train = x_train.to(device)\n",
    "    \n",
    "    print(\"++++++++\")\n",
    "    print(x_train.type())\n",
    "\n",
    "    x_data = {'train': x_train, 'val': x_val, 'test': x_test}\n",
    "    dataset = Dataset(x_data, x_stats)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "{'mean': tensor(58.4998), 'std': tensor(13.7286)}\n",
      "++++++++\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "print(data_file_tensor.type())\n",
    "PeMS = data_gen(data_file_tensor, (n_train, n_val, n_test), n_route, n_hist + n_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem\n",
    "\n",
    "def layer_norm(x):\n",
    "    '''\n",
    "    Layer normalization function.\n",
    "    :param x: tensor, [batch_size, channel, time_step, n_route].\n",
    "    :return: tensor, [batch_size, channel, time_step, n_route].\n",
    "    '''\n",
    "    _, C, _, N = x.size()\n",
    "    mu, sigma = torch.mean(x, dim=[2, 3], keepdim=True), torch.var(x, dim=[2, 3], keepdim=True)\n",
    "\n",
    "    gamma = torch.ones([1, C, 1, N])\n",
    "    beta = torch.zeros([1, C, 1, N])\n",
    "    # big problem\n",
    "    _x = (x - mu) / torch.sqrt(sigma + 1e-6) # * gamma + beta\n",
    "    \n",
    "    return _x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 3])\n",
      "tensor([[[[1.3987, 1.5512, 1.7037],\n",
      "          [1.8561, 2.0086, 2.1611]]],\n",
      "\n",
      "\n",
      "        [[[3.2284, 3.3809, 3.5334],\n",
      "          [3.6858, 3.8383, 3.9908]]]], grad_fn=<ThnnConv2DBackward>)\n",
      "torch.Size([2, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "test = torch.Tensor([[[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]], [[[13, 14, 15], [16, 17, 18]], \n",
    "                                                                           [[19, 20, 21], [22, 23, 24]]]])\n",
    "\n",
    "print(test.size())\n",
    "a = torch.nn.Conv2d(2, 1, (1, 1), stride=[1, 1])(test)\n",
    "print(a)\n",
    "print(a.size())\n",
    "# print(layer_norm(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ST_Network(torch.nn.Module):\n",
    "    def __init__(self, n_his, Ks, Kt, rate, Lk, Ko):\n",
    "        '''\n",
    "        Build the base model.\n",
    "        :param n_his: int, size of historical records for training.\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param blocks: list, channel configs of st_conv blocks.\n",
    "        :param rate: the rate of dropout.\n",
    "        '''\n",
    "        super(ST_Network, self).__init__()\n",
    "        self.n_his = n_his\n",
    "        self.Ks = Ks\n",
    "        self.Kt = Kt\n",
    "        self.rate = rate\n",
    "        self.Lk = Lk\n",
    "        self.Ko = Ko\n",
    "        \n",
    "        print(\"self.Lk\")\n",
    "        print(self.Lk.type())\n",
    "        \n",
    "        # blocks = [1, 32, 64], [64, 32, 128]\n",
    "        # take a look at the link below for quick reminder of padding, stride and dilation\n",
    "        # https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md \n",
    "        # stride=[1, 1] means no stride\n",
    "        # padding=[0, 0] means no padding or \"Valid\"\n",
    "        # dilation=[1, 1] means no dilation\n",
    "        self.Conv2DBlock1Temporal1GLU = torch.nn.Conv2d(1, 2 * 32, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidBlock1Temporal1 = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.ThetaBlock1Spatio = torch.nn.Parameter(torch.rand((self.Ks * 32, 32), requires_grad=True)) # problem device and dtype\n",
    "        self.ReLUBlock1Spatio = torch.nn.ReLU()\n",
    "        \n",
    "        self.Conv2DBlock1Temporal2ReLU = torch.nn.Conv2d(32, 64, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.ReLUBlock1Temporal2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.DropoutBlock1 = torch.nn.Dropout(p=rate)\n",
    "        \n",
    "        # problem\n",
    "        # the size of kernel is one so SAME padding is meaningless\n",
    "        self.Conv2DBlock2Temporal1 = torch.nn.Conv2d(64, 32, (1, 1), stride=[1, 1])\n",
    "        self.Conv2DBlock2Temporal1GLU = torch.nn.Conv2d(64, 2 * 32, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidBlock2Temporal1 = torch.nn.Sigmoid()\n",
    "        \n",
    "        self.ThetaBlock2Spatio = torch.nn.Parameter(torch.rand((self.Ks * 32, 32), requires_grad=True)) # problem device and dtype\n",
    "        self.ReLUBlock2Spatio = torch.nn.ReLU()\n",
    "        \n",
    "        self.Conv2DBlock2Temporal2ReLU = torch.nn.Conv2d(32, 128, (Kt, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.ReLUBlock2Temporal2 = torch.nn.ReLU()\n",
    "        \n",
    "        self.DropoutBlock2 = torch.nn.Dropout(p=rate)\n",
    "        \n",
    "        self.Conv2DOutputTemporal1GLU = torch.nn.Conv2d(128, 2 * 128, (Ko, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidOutputTemporal1 = torch.nn.Sigmoid()\n",
    "        self.Conv2DOutputTemporal2Sigmoid = torch.nn.Conv2d(128, 128, (1, 1), stride=[1, 1], padding=[0, 0], dilation=[1, 1])\n",
    "        self.SigmoidOutputTemporal2 = torch.nn.Sigmoid()\n",
    "        # problem\n",
    "        # the size of kernel is one so SAME padding is meaningless\n",
    "        self.FullyConnectedLayer = torch.nn.Conv2d(128, 1, (1, 1), stride=[1, 1], dilation=[1, 1])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Ko>0: kernel size of temporal convolution in the output layer.\n",
    "        Ko = self.n_his\n",
    "        \n",
    "#         print(\"forward\")\n",
    "#         print(x.type())\n",
    "        \n",
    "        # ST-Block\n",
    "        # [1, 32, 64]\n",
    "        x = self.st_conv_block1(x)\n",
    "        \n",
    "        # [64, 32, 128]\n",
    "        x = self.st_conv_block2(x)         \n",
    "\n",
    "        # Output Layer\n",
    "        y = self.output_layer(x)\n",
    "\n",
    "        #     tf.add_to_collection(name='copy_loss',\n",
    "        #                          value=tf.nn.l2_loss(y - inputs[:, n_his:n_his + 1, :, :]))\n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "#         train_loss = loss_fn(y, inputs[:, :, n_his:n_his + 1, :])\n",
    "#         single_pred = y[:, 0, :, :]\n",
    "        #     tf.add_to_collection(name='y_pred', value=single_pred)\n",
    "#         return train_loss, single_pred\n",
    "        return y\n",
    "\n",
    "    def st_conv_block1(self, x):\n",
    "        '''\n",
    "        Spatio-temporal convolutional block, which contains two temporal gated convolution layers\n",
    "        and one spatial graph convolution layer in the middle.\n",
    "        :param x: tensor, batch_size, time_step, n_route, c_in].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param channels: list, channel configs of a single st_conv block.\n",
    "        :param scope: str, variable scope.\n",
    "        :param keep_prob: placeholder, prob of dropout.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, time_step, n_route, c_out].\n",
    "        '''\n",
    "        \n",
    "        x_s = self.block1Temporal1(x)\n",
    "        x_t = self.block1Spatio(x_s)\n",
    "        x_o = self.block1Temporal2(x_t)\n",
    "        x_ln = layer_norm(x_o)\n",
    "    \n",
    "        return self.DropoutBlock1(x_ln)\n",
    "    \n",
    "    def block1Temporal1(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 32 - 1, T, n]).to(device)], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        # this is a bad code. We want to use this for residual connections and in order to do \n",
    "        # that the dimentions should match so we use \"self.Kt - 1:T\" just to fix this problem \n",
    "        # but we are actually just deleting the first time steps which actually makes a little \n",
    "        # sense that we are careing about nearer time steps \n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DBlock1Temporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:32, :, :] + x_input)\n",
    "        q = x_conv[:, -32:, :, :]\n",
    "\n",
    "        return p * self.SigmoidBlock1Temporal1(q)\n",
    "    \n",
    "    def block1Spatio(self, x):\n",
    "        '''\n",
    "        Spatial graph convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :return: tensor, [batch_size, c_out, time_step, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "        \n",
    "        x_input = x\n",
    "\n",
    "    #     variable_summaries(ws, 'theta')\n",
    "        bs = torch.zeros((32))\n",
    "        # x -> [batch_size, c_in, time_step, n_route] -> [batch_size, time_step, c_in, n_route]\n",
    "        # x -> [batch_size, time_step, c_in, n_route] -> [batch_size*time_step, c_in, n_route]\n",
    "        # x -> [batch_size*time_step, c_in, n_route] -> [batch_size*time_step, c_out, n_route]\n",
    "        a = torch.reshape(torch.transpose(x, 1, 2), [-1, 32, n])\n",
    "        x_gconv = self.gconv(a, self.ThetaBlock1Spatio, self.Ks, 32, 32, self.Lk)# + bs\n",
    "        # [batch_size*time_step, c_out, n_route] -> [batch_size, time_step, c_out, n_route]\n",
    "        # [batch_size, time_step, c_out, n_route] -> [batch_size, c_out, time_step, n_route]\n",
    "        x_gc = torch.transpose(torch.reshape(x_gconv, [-1, T, 32, n]), 1, 2)\n",
    "        \n",
    "        return self.ReLUBlock1Spatio(x_gc[:, :, :, :] + x_input)\n",
    "    \n",
    "    def block1Temporal2(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 64 - 32, T, n]).to(device)], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        x_conv = self.Conv2DBlock1Temporal2ReLU(x)\n",
    "        \n",
    "        return self.ReLUBlock1Temporal2(x_conv + x_input)\n",
    "\n",
    "    def st_conv_block2(self, x):\n",
    "        '''\n",
    "        Spatio-temporal convolutional block, which contains two temporal gated convolution layers\n",
    "        and one spatial graph convolution layer in the middle.\n",
    "        :param x: tensor, batch_size, time_step, n_route, c_in].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param channels: list, channel configs of a single st_conv block.\n",
    "        :param scope: str, variable scope.\n",
    "        :param keep_prob: placeholder, prob of dropout.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, time_step, n_route, c_out].\n",
    "        '''     \n",
    "        x_s = self.block2Temporal1(x)\n",
    "        x_t = self.block2Spatio(x_s)\n",
    "        x_o = self.block2Temporal2(x_t)\n",
    "        x_ln = layer_norm(x_o)\n",
    "    \n",
    "        return self.DropoutBlock2(x_ln)\n",
    "    \n",
    "    def block2Temporal1(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "#       PyTorch does not support same padding the way Keras does\n",
    "#       padding='SAME'\n",
    "        x_input = self.Conv2DBlock2Temporal1(x)\n",
    "\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DBlock2Temporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:32, :, :] + x_input)\n",
    "        q = x_conv[:, -32:, :, :]\n",
    "\n",
    "        return p * self.SigmoidBlock2Temporal1(q)  \n",
    "\n",
    "    def block2Spatio(self, x):\n",
    "        '''\n",
    "        Spatial graph convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Ks: int, kernel size of spatial convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :return: tensor, [batch_size, c_out, time_step, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "        \n",
    "        x_input = x\n",
    "\n",
    "    #     variable_summaries(ws, 'theta')\n",
    "        bs = torch.zeros((32))\n",
    "        # x -> [batch_size, c_in, time_step, n_route] -> [batch_size, time_step, c_in, n_route]\n",
    "        # x -> [batch_size, time_step, c_in, n_route] -> [batch_size*time_step, c_in, n_route]\n",
    "        # x -> [batch_size*time_step, c_in, n_route] -> [batch_size*time_step, c_out, n_route]\n",
    "        x_gconv = self.gconv(torch.reshape(torch.transpose(x, 1, 2), [-1, 32, n]), self.ThetaBlock2Spatio, \n",
    "                             self.Ks, 32, 32, self.Lk)# + bs problem\n",
    "        # [batch_size*time_step, c_out, n_route] -> [batch_size, time_step, c_out, n_route]\n",
    "        # [batch_size, time_step, c_out, n_route] -> [batch_size, c_out, time_step, n_route]\n",
    "        x_gc = torch.transpose(torch.reshape(x_gconv, [-1, T, 32, n]), 1, 2)\n",
    "        \n",
    "        return self.ReLUBlock2Spatio(x_gc[:, :, :, :] + x_input)\n",
    "        \n",
    "    def block2Temporal2(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''   \n",
    "        _, _, T, n = x.size()\n",
    "\n",
    "        # if the size of input channel is less than the output,\n",
    "        # padding x to the same size of output channel.\n",
    "        # Note, _.get_shape() cannot convert a partially known TensorShape to a Tensor.\n",
    "        x_input = torch.cat([x, torch.zeros([x.size()[0], 128 - 32, T, n]).to(device)], axis=1)\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Kt - 1:T, :]\n",
    "        \n",
    "        x_conv = self.Conv2DBlock2Temporal2ReLU(x)\n",
    "\n",
    "        return self.ReLUBlock2Temporal2(x_conv + x_input)\n",
    "\n",
    "    def output_layer(self, x):\n",
    "        '''\n",
    "        Output layer: temporal convolution layers attach with one fully connected layer,\n",
    "        which map outputs of the last st_conv block to a single-step prediction.\n",
    "        :param x: tensor, [batch_size, channel, time_step, n_route].\n",
    "        :param T: int, kernel size of temporal convolution.\n",
    "        :param scope: str, variable scope.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, 1, n_route, 1].\n",
    "        '''\n",
    "        # maps multi-steps to one.\n",
    "        x_i = self.output_layer_temp1_GLU(x)\n",
    "        x_ln = layer_norm(x_i)\n",
    "        x_o = self.output_layer_temp2_sigmoid(x_ln)            \n",
    "            \n",
    "        # maps multi-channels to one.\n",
    "        x_fc = self.fully_con_layer(x_o)\n",
    "        \n",
    "        return x_fc\n",
    "    \n",
    "    def output_layer_temp1_GLU(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "        \n",
    "        x_input = x\n",
    "        \n",
    "        # keep the original input for residual connection.\n",
    "        x_input = x_input[:, :, self.Ko - 1:T, :]\n",
    "        \n",
    "        # gated liner unit\n",
    "    #   tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(wt))\n",
    "    #   is it really the same as padding= 'valid'\n",
    "        x_conv = self.Conv2DOutputTemporal1GLU(x)\n",
    "        \n",
    "        p = (x_conv[:, 0:128, :, :] + x_input)\n",
    "        q = x_conv[:, -128:, :, :]\n",
    "\n",
    "        return p * self.SigmoidOutputTemporal1(q)\n",
    "    \n",
    "    def output_layer_temp2_sigmoid(self, x):\n",
    "        '''\n",
    "        Temporal convolution layer.\n",
    "        :param x: tensor, [batch_size, c_in, time_step, n_route].\n",
    "        :param Kt: int, kernel size of temporal convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :param act_func: str, activation function.\n",
    "        :return: tensor, [batch_size, c_out, time_step-Kt+1, n_route].\n",
    "        '''\n",
    "        _, _, T, n = x.size()\n",
    "        \n",
    "        x_conv = self.Conv2DOutputTemporal2Sigmoid(x)\n",
    "        \n",
    "        return self.SigmoidOutputTemporal2(x_conv)\n",
    "\n",
    "    def fully_con_layer(self, x):\n",
    "        '''\n",
    "        Fully connected layer: maps multi-channels to one.\n",
    "        :param x: tensor, [batch_size, channel, 1, n_route].\n",
    "        :param n: int, number of route / size of graph.\n",
    "        :param channel: channel size of input x.\n",
    "        :return: tensor, [batch_size, 1, n_route, 1].\n",
    "        '''\n",
    "    #     tf.add_to_collection(name='weight_decay', value=tf.nn.l2_loss(w))\n",
    "    #     PyTorch does not support same padding the way Keras does\n",
    "    #     padding='SAME'\n",
    "        return self.FullyConnectedLayer(x)\n",
    "    \n",
    "    # problem\n",
    "    def gconv(self, x, theta, Ks, c_in, c_out, kernel):\n",
    "        '''\n",
    "        Spectral-based graph convolution function.\n",
    "        :param x: tensor, [batch_size, c_in, n_route].\n",
    "        :param theta: tensor, [Ks*c_in, c_out], trainable kernel parameters.\n",
    "        :param Ks: int, kernel size of graph convolution.\n",
    "        :param c_in: int, size of input channel.\n",
    "        :param c_out: int, size of output channel.\n",
    "        :return: tensor, [batch_size, n_route, c_out].\n",
    "        '''\n",
    "        # graph kernel: tensor, [n_route, Ks*n_route]\n",
    "        n = kernel.shape[0]\n",
    "        # x -> [batch_size, c_in, n_route] -> [batch_size*c_in, n_route]\n",
    "        x_tmp = torch.reshape(x, [-1, n])\n",
    "        # x_mul = x_tmp * ker -> [batch_size*c_in, Ks*n_route] -> [batch_size, c_in, Ks, n_route]\n",
    "#         print(\"x_tmp\")\n",
    "#         print(x_tmp.type())\n",
    "#         print(\"kernel\")\n",
    "#         print(kernel.type())\n",
    "        x_mul = torch.reshape(torch.matmul(x_tmp, kernel), [-1, c_in, Ks, n]) # problem should kernel's \n",
    "        # requires_grad be true and be on GPU\n",
    "        # [batch_size, c_in, Ks, n_route] -> [batch_size, n_route, Ks, c_in]\n",
    "        # [batch_size, n_route, Ks, c_in] -> [batch_size, n_route, c_in, Ks]\n",
    "        # x_ker -> [batch_size, n_route, c_in, K_s] -> [batch_size*n_route, c_in*Ks]\n",
    "        x_ker = torch.reshape(torch.transpose(torch.transpose(x_mul, 1, 3), 2, 3), [-1, c_in * Ks])\n",
    "        # x_gconv -> [batch_size*n_route, c_out] -> [batch_size, n_route, c_out]\n",
    "#         print(\"x_ker\")\n",
    "#         print(x_ker.type())\n",
    "#         print(\"theta\")\n",
    "#         print(theta.type())\n",
    "        x_gconv = torch.reshape(torch.matmul(x_ker, theta), [-1, n, c_out])\n",
    "        # [batch_size, n_route, c_out] -> [batch_size, c_out, n_route]\n",
    "        x_gconv = torch.transpose(x_gconv, 1, 2) # I added this line, maybe we can also reshape to [-1, c_out, n] in \n",
    "        # the previous line instead\n",
    "        return x_gconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.Lk\n",
      "torch.cuda.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "model = ST_Network(n_hist, ks, kt, rate, Lk, Ko).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model, loss_fn, optimizer):\n",
    "    def train_step(x, y):\n",
    "        # put model in training mode \n",
    "        # some models may use mechanisms like Dropout, for instance, which have distinct behaviors in \n",
    "        # training and evaluation phase\n",
    "        model.train()\n",
    "        \n",
    "        # compute the model output\n",
    "        yhat = model(x)\n",
    "        \n",
    "        # calculate loss\n",
    "#         print(type(yhat))\n",
    "#         print(yhat.size())\n",
    "#         print(\"x_batch[:, :, n_hist-2:, :]\")\n",
    "#         print(x_batch[:, :, n_hist-2:, :].size())\n",
    "        # todo the dimention of yhat is wrong. its dimention 2 value should be 9 not 10\n",
    "        loss = loss_fn(y, yhat)\n",
    "#         print(loss)\n",
    "        \n",
    "        # compute gradients\n",
    "        loss.backward()\n",
    "    \n",
    "        # update model weights\n",
    "        optimizer.step()  \n",
    "        # clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        return loss.item()  # the .item() is so important or we'll have problem with memory\n",
    "    \n",
    "    # Returns the function that will be calculated inside the train loop\n",
    "    return train_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(inputs, model, epoch, n_hist):\n",
    "    # Define model loss\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    # define the optimization\n",
    "    # torch.optim.Adam(lr, weight_decay=0.01).minimize(train_loss)\n",
    "    optimizer = opt(model.parameters(), lr=lr)\n",
    "    schedular = sch(optimizer, gamma=decay)\n",
    "    \n",
    "    train_step = make_train_step(model, criterion, optimizer)\n",
    "    losses = []\n",
    "    \n",
    "    # enumerate epochs     \n",
    "    for i in range(epoch):\n",
    "        start_time = time.time()\n",
    "        data_loader = DataLoader(inputs.get_data('train'),\n",
    "                                 batch_size=batch_size, # where did I define batch size\n",
    "                                 drop_last=True)\n",
    "        # gen_batch(inputs.get_data('train'), batch_size, dynamic_batch=True, shuffle=True)\n",
    "        # enumerate mini batches\n",
    "        for _, x_batch in enumerate(data_loader):\n",
    "            # x dimention = [batch_size, channel = 1, n_frame, n_route]\n",
    "            # n_hist = 12\n",
    "            x = x_batch[:, :, 0:n_hist, :]\n",
    "            \n",
    "            # Performs one train step and returns the corresponding loss\n",
    "            print(\"y\")\n",
    "            print(x_batch[:, :, n_hist:n_hist+1, :].size())\n",
    "            loss = train_step(x, x_batch[:, :, n_hist, :])\n",
    "            losses.append(loss)\n",
    "        \n",
    "#         print(model.state_dict())\n",
    "        print(f'Epoch {i:2d} Training Time {time.time() - start_time:.3f}s')\n",
    "    \n",
    "        schedular.step()\n",
    "\n",
    "#         start_time = time.time()\n",
    "#         min_va_val, min_val = \\\n",
    "#                 model_inference(sess, pred, inputs, batch_size, n_his, n_pred, step_idx, min_va_val, min_val)\n",
    "\n",
    "            \n",
    "#         loss = loss_fn(predictions, t)\n",
    "#       train_op.step()\n",
    "#         for ix in tmp_idx:\n",
    "#             va, te = min_va_val[ix - 2:ix + 1], min_val[ix - 2:ix + 1]\n",
    "#             print(f'Time Step {ix + 1}: '\n",
    "#                     f'MAPE {va[0]:7.3%}, {te[0]:7.3%}; '\n",
    "#                     f'MAE  {va[1]:4.3f}, {te[1]:4.3f}; '\n",
    "#                     f'RMSE {va[2]:6.3f}, {te[2]:6.3f}.')\n",
    "#         print(f'Epoch {i:2d} Inference Time {time.time() - start_time:.3f}s')\n",
    "\n",
    "#         if (i + 1) % save == 0 || (i + 1) == epoch:\n",
    "        torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n",
      "y\n",
      "torch.Size([50, 1, 1, 228])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-10bfc83025bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPeMS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# todo the problem was model.parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-0639dc5b1f9c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(inputs, model, epoch, n_hist)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_hist\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-cf18ec20ff72>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the .item() is so important or we'll have problem with memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Returns the function that will be calculated inside the train loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(PeMS, model, epoch, n_hist)\n",
    "# todo the problem was model.parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"tensorflow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_pred(model, y_pred, seq, batch_size, n_his, n_pred, step_idx, dynamic_batch=True):\n",
    "#     '''\n",
    "#     Multi_prediction function.\n",
    "#     :param y_pred: placeholder.\n",
    "#     :param seq: np.ndarray, [len_seq, n_frame, n_route, C_0].\n",
    "#     :param batch_size: int, the size of batch.\n",
    "#     :param n_his: int, size of historical records for training.\n",
    "#     :param n_pred: int, the length of prediction.\n",
    "#     :param step_idx: int or list, index for prediction slice.\n",
    "#     :param dynamic_batch: bool, whether changes the batch size in the last one if its length is less than the default.\n",
    "#     :return y_ : tensor, 'sep' [len_inputs, n_route, 1]; 'merge' [step_idx, len_inputs, n_route, 1].\n",
    "#             len_ : int, the length of prediction.\n",
    "#     '''\n",
    "#     pred_list = []\n",
    "#     for batch in gen_batch(seq, min(batch_size, len(seq)), dynamic_batch=dynamic_batch):\n",
    "#         # Note: use np.copy() to avoid the modification of source data.\n",
    "#         test_seq = torch.copy(batch[:, :, 0:n_his, :])\n",
    "#         step_list = []\n",
    "# #         for j in range(n_pred):\n",
    "#             pred = model(test_seq)\n",
    "# #             pred = sess.run(y_pred,\n",
    "# #                             feed_dict={'data_input:0': , 'keep_prob:0': 1.0})\n",
    "# #             if isinstance(pred, list):\n",
    "# #                 pred = np.array(pred[0])\n",
    "#             # move the window to predict the next 9 time steps\n",
    "# #             test_seq[:, :, 0:n_his - 1, :] = test_seq[:, :, 1:n_his, :]\n",
    "# #             test_seq[:, :, n_his - 1, :] = pred\n",
    "#             step_list.append(pred)\n",
    "#         pred_list.append(step_list)\n",
    "#     #  pred_array -> [n_pred, batch_size, n_route, C_0)\n",
    "#     pred_array = np.concatenate(pred_list, axis=1)\n",
    "#     return pred_array[step_idx], pred_array.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[[[[1], [2]], [[3], [4]]], [[[5], [6]], [[7], [8]]]]]\n",
    "print(a)\n",
    "print(np.concatenate(a, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(inputs, batch_size, n_his, n_pred, inf_mode):\n",
    "    '''\n",
    "    Load and test saved model from the checkpoint.\n",
    "    :param inputs: instance of class Dataset, data source for test.\n",
    "    :param batch_size: int, the size of batch.\n",
    "    :param n_his: int, the length of historical records for training.\n",
    "    :param n_pred: int, the length of prediction.\n",
    "    :param inf_mode: str, test mode - 'merge / multi-step test' or 'separate / single-step test'.\n",
    "    :param load_path: str, the path of loaded model.\n",
    "    '''\n",
    "    start_time = time.time()\n",
    "\n",
    "    model = ST_Network(n_hist, ks, kt, rate, Lk, Ko).to(device)\n",
    "    # the load_state_dict() function takes a dictionary object not a path to a saved object\n",
    "    model.load_state_dict(torch.load(\"model.pt\"))\n",
    "        \n",
    "    # to set dropout and batch normalization layers to evaluation mode before running inference\n",
    "    model.eval()\n",
    "    print(f'>> Loading saved model from model.pt ...')\n",
    "\n",
    "    # don't care about the further times at the moment\n",
    "#        if inf_mode == 'sep':\n",
    "#            # for inference mode 'sep', the type of step index is int.\n",
    "#            step_idx = n_pred - 1\n",
    "#            tmp_idx = [step_idx]\n",
    "#        elif inf_mode == 'merge':\n",
    "#            # for inference mode 'merge', the type of step index is np.ndarray.\n",
    "#            step_idx = tmp_idx = np.arange(3, n_pred + 1, 3) - 1\n",
    "#        else:\n",
    "#            raise ValueError(f'ERROR: test mode \"{inf_mode}\" is not defined.')\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    # without making the data into batches we'll have cuda out of memory error\n",
    "#     for batch in gen_batch(seq, min(batch_size, len(seq)), dynamic_batch=dynamic_batch):\n",
    "    x_stats = inputs.get_stats()\n",
    "    data_loader = DataLoader(inputs.get_data('test'),\n",
    "                                 batch_size=10, # where did I define batch size\n",
    "                                 drop_last=True)\n",
    "        # gen_batch(inputs.get_data('train'), batch_size, dynamic_batch=True, shuffle=True)\n",
    "        # enumerate mini batches\n",
    "    for _, x_batch in enumerate(data_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "#         y_test, len_test = multi_pred(model, pred, x_test, batch_size, n_his, n_pred, step_idx)\n",
    "        pred = model(x_batch)\n",
    "#         evl = evaluation(x_test[0:len_test, step_idx + n_his, :, :], y_test, x_stats)\n",
    "\n",
    "#         for ix in tmp_idx:\n",
    "#             te = evl[ix - 2:ix + 1]\n",
    "#             print(f'Time Step {ix + 1}: MAPE {te[0]:7.3%}; MAE  {te[1]:4.3f}; RMSE {te[2]:6.3f}.')\n",
    "           \n",
    "        loss = loss_fn(x_batch[:, :, n_his, :], pred)\n",
    "        print(loss.item()) #, MAE(v, v_), RMSE(v, v_)])\n",
    "    \n",
    "    print(f'Model Test Time {time.time() - start_time:.3f}s')\n",
    "    print('Testing model finished!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_test(PeMS, PeMS.get_len('test'), n_hist, n_pred, inf_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
